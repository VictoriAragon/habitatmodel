{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within this notebook are the US states boundaries and US counties boundaries download. \n",
    "\n",
    "Also included is \n",
    "\n",
    "    Kiowa National Grassland\n",
    "\n",
    "    \n",
    "    Pawnee National Grassland\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to restore variable 'band_dict', ignoring (use %store -d to forget!)\n",
      "The error was: <class 'KeyError'>\n",
      "Unable to restore variable 'ndvi_da', ignoring (use %store -d to forget!)\n",
      "The error was: <class 'KeyError'>\n"
     ]
    }
   ],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import os\n",
    "import requests\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading the US States and US counties data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#counties and state download\n",
    "\n",
    "#make us states folder\n",
    "os.makedirs(\"C:/Users/arago/Documents/GitHub/habitatmodel-main/studyarea_data/us_states\", exist_ok=True)\n",
    "\n",
    "#make us counties folder\n",
    "os.makedirs(\"C:/Users/arago/Documents/GitHub/habitatmodel-main/studyarea_data/us_counties\", exist_ok=True)\n",
    "\n",
    "#combine path components into a single path\n",
    "us_states=os.path.join(\"C:/Users/arago/Documents/GitHub/habitatmodel-main/studyarea_data/us_states\")\n",
    "\n",
    "#combine path components into a single path\n",
    "us_counties=os.path.join(\"C:/Users/arago/Documents/GitHub/habitatmodel-main/studyarea_data/us_counties\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating variable and directories for the downloaded states and counties zip file\n",
    "\n",
    "us_states_url=\"https://www2.census.gov/geo/tiger/GENZ2018/shp/cb_2018_us_state_5m.zip\"\n",
    "us_counties_url=\"https://www2.census.gov/geo/tiger/GENZ2018/shp/cb_2018_us_county_5m.zip\"\n",
    "states_file_name=\"cb_2018_us_state_5m.zip\"\n",
    "counties_file_name=\"cb_2018_us_state_5m.zip\"\n",
    "\n",
    "#states directory creation\n",
    "us_states_dir= os.path.join(us_states, 'us_states_bound')\n",
    "os.makedirs(us_states_dir, exist_ok=True)\n",
    "\n",
    "us_states_zip_path= os.path.join(us_states_dir, states_file_name)\n",
    "us_states_path=os.path.join(us_states_dir,'us_states_bound')\n",
    "\n",
    "#counties directory creation\n",
    "us_counties_dir= os.path.join(us_counties, 'us_counties_bound')\n",
    "os.makedirs(us_counties_dir, exist_ok=True)\n",
    "\n",
    "us_counties_zip_path= os.path.join(us_counties_dir, counties_file_name)\n",
    "us_counties_path=os.path.join(us_counties_dir,'us_counties_bound')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZIP file already exists at: C:/Users/arago/Documents/GitHub/habitatmodel-main/studyarea_data/us_states\\us_states_bound\\cb_2018_us_state_5m.zip\n",
      "Extracting C:/Users/arago/Documents/GitHub/habitatmodel-main/studyarea_data/us_states\\us_states_bound\\cb_2018_us_state_5m.zip...\n",
      "Contents extracted to: C:/Users/arago/Documents/GitHub/habitatmodel-main/studyarea_data/us_states\\us_states_bound\n"
     ]
    }
   ],
   "source": [
    "#STATE BOUNDARIES DOWNLOAD AND UNZIP\n",
    "#  \n",
    "#Used chatgpt to correct this section since my previous created script was not working\n",
    "\n",
    "#Downloading the zip file data and extracting the data to the set directory\n",
    "\n",
    "# Function to download the state US  ZIP file\n",
    "def download_file(url, us_states_dir):\n",
    "    try:\n",
    "        print(f\"Downloading from  website: {url}\")\n",
    "        response = requests.get(url, stream=True)\n",
    "        response.raise_for_status()  # Raise HTTPError for bad responses\n",
    "        \n",
    "        # Save the file in chunks\n",
    "        with open(us_states_dir, \"wb\") as file:\n",
    "            for chunk in response.iter_content(chunk_size=1024):\n",
    "                if chunk:  # Filter out keep-alive chunks\n",
    "                    file.write(chunk)\n",
    "        print(f\"File downloaded and saved to: {us_states_dir}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error downloading file: {e}\")\n",
    "\n",
    "# Function to extract ZIP file\n",
    "def extract_zip(zip_file_path, extract_to):\n",
    "    try:\n",
    "        print(f\"Extracting {zip_file_path}...\")\n",
    "        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_to)\n",
    "        print(f\"Contents extracted to: {extract_to}\")\n",
    "    except zipfile.BadZipFile as e:\n",
    "        print(f\"Error: The file is not a valid ZIP archive: {e}\")\n",
    "\n",
    "# Step 1: Download the ZIP file\n",
    "if not os.path.exists(us_states_zip_path):\n",
    "    download_file(us_states_url, us_states_zip_path)\n",
    "else:\n",
    "    print(f\"ZIP file already exists at: {us_states_zip_path}\")\n",
    "\n",
    "# Step 2: Extract the ZIP file\n",
    "if not os.path.exists(us_states_path):\n",
    "    extract_zip(us_states_zip_path, us_states_dir)\n",
    "else:\n",
    "    print(f\"Extracted directory already exists at: {us_states_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZIP file already exists at: C:/Users/arago/Documents/GitHub/habitatmodel-main/studyarea_data/us_counties\\us_counties_bound\\cb_2018_us_state_5m.zip\n",
      "Extracting C:/Users/arago/Documents/GitHub/habitatmodel-main/studyarea_data/us_counties\\us_counties_bound\\cb_2018_us_state_5m.zip...\n",
      "Contents extracted to: C:/Users/arago/Documents/GitHub/habitatmodel-main/studyarea_data/us_counties\\us_counties_bound\n"
     ]
    }
   ],
   "source": [
    "#COUNTIES BOUNDARIES DOWNLOAD AND UNZIP\n",
    "\n",
    "#Used chatgpt to correct this section since my previous created script was not working\n",
    "\n",
    "#Downloading the zip file data and extracting the data to the set directory\n",
    "\n",
    "# Function to download the counties US  ZIP file\n",
    "def download_file(url, us_counties_dir):\n",
    "    try:\n",
    "        print(f\"Downloading from  website: {url}\")\n",
    "        response = requests.get(url, stream=True)\n",
    "        response.raise_for_status()  # Raise HTTPError for bad responses\n",
    "        \n",
    "        # Save the file in chunks\n",
    "        with open(us_counties_dir, \"wb\") as file:\n",
    "            for chunk in response.iter_content(chunk_size=1024):\n",
    "                if chunk:  # Filter out keep-alive chunks\n",
    "                    file.write(chunk)\n",
    "        print(f\"File downloaded and saved to: {us_counties_dir}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error downloading file: {e}\")\n",
    "\n",
    "# Function to extract ZIP file\n",
    "def extract_zip(zip_file_path, extract_to):\n",
    "    try:\n",
    "        print(f\"Extracting {zip_file_path}...\")\n",
    "        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_to)\n",
    "        print(f\"Contents extracted to: {extract_to}\")\n",
    "    except zipfile.BadZipFile as e:\n",
    "        print(f\"Error: The file is not a valid ZIP archive: {e}\")\n",
    "\n",
    "# Step 1: Download the ZIP file\n",
    "if not os.path.exists(us_counties_zip_path):\n",
    "    download_file(us_counties_url, us_counties_zip_path)\n",
    "else:\n",
    "    print(f\"ZIP file already exists at: {us_counties_zip_path}\")\n",
    "\n",
    "# Step 2: Extract the ZIP file\n",
    "if not os.path.exists(us_counties_path):\n",
    "    extract_zip(us_counties_zip_path, us_counties_dir)\n",
    "else:\n",
    "    print(f\"Extracted directory already exists at: {us_counties_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['STATEFP', 'STATENS', 'AFFGEOID', 'GEOID', 'STUSPS', 'NAME', 'LSAD',\n",
      "       'ALAND', 'AWATER', 'geometry'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arago\\miniconda3\\Lib\\site-packages\\pyogrio\\core.py:35: RuntimeWarning: Could not detect GDAL data files.  Set GDAL_DATA environment variable to the correct path.\n",
      "  _init_gdal_data()\n"
     ]
    }
   ],
   "source": [
    "#checking the states shapefile contents\n",
    "\n",
    "#defining the shapefile path\n",
    "states_shp_path= r\"C:\\Users\\arago\\Documents\\GitHub\\habitatmodel-main\\studyarea_data\\us_states\\us_states_bound\\cb_2018_us_state_5m.shp\"\n",
    "\n",
    "#loading the shapefile\n",
    "states_gdf=gpd.read_file(states_shp_path)\n",
    "\n",
    "print(states_gdf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   STATEFP   STATENS     AFFGEOID GEOID STUSPS        NAME LSAD         ALAND  \\\n",
      "2       35  00897535  0400000US35    35     NM  New Mexico   00  314196306401   \n",
      "31      08  01779779  0400000US08    08     CO    Colorado   00  268422891711   \n",
      "\n",
      "        AWATER  \n",
      "2    728776523  \n",
      "31  1181621593  \n"
     ]
    }
   ],
   "source": [
    "#checking the states shapefiles contents in a more structured way by defining the dataframe and printing it\n",
    "\n",
    "states_gdf=gpd.read_file(states_shp_path)\n",
    "\n",
    "#converting the gdf to pandas dataframe so I can read the structure of the table\n",
    "states_df= states_gdf.drop(columns='geometry')\n",
    "\n",
    "#filter to only show NM and CO\n",
    "filtered_states = states_df[states_df['NAME'].isin(['Colorado', 'New Mexico'])]\n",
    "\n",
    "# Display the filtered rows\n",
    "print(filtered_states)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['STATEFP', 'COUNTYFP', 'COUNTYNS', 'AFFGEOID', 'GEOID', 'NAME', 'LSAD',\n",
      "       'ALAND', 'AWATER', 'geometry'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#checking the counties shapefile contents\n",
    "\n",
    "#defining the shapefile path\n",
    "counties_shp_path= r\"C:\\Users\\arago\\Documents\\GitHub\\habitatmodel-main\\studyarea_data\\us_counties\\us_counties_bound\\cb_2018_us_county_5m.shp\"\n",
    "\n",
    "#loading the shapefile\n",
    "counties_gdf=gpd.read_file(counties_shp_path)\n",
    "\n",
    "print(counties_gdf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     STATEFP COUNTYFP  COUNTYNS        AFFGEOID  GEOID     NAME LSAD  \\\n",
      "1681      35      007  00929117  0500000US35007  35007   Colfax   06   \n",
      "2203      35      033  01702367  0500000US35033  35033     Mora   06   \n",
      "2387      35      021  00933055  0500000US35021  35021  Harding   06   \n",
      "2818      08      123  00198177  0500000US08123  08123     Weld   06   \n",
      "\n",
      "            ALAND    AWATER  \n",
      "1681   9733110158  26299632  \n",
      "2203   4988962798   6093304  \n",
      "2387   5504963126   1162620  \n",
      "2818  10323763901  79558364  \n"
     ]
    }
   ],
   "source": [
    "#checking the COUNTIES shapefiles contents in a more structured way by defining the dataframe and printing it\n",
    "\n",
    "counties_gdf=gpd.read_file(counties_shp_path)\n",
    "\n",
    "#converting the gdf to pandas dataframe so I can read the structure of the table\n",
    "counties_df= counties_gdf.drop(columns='geometry')\n",
    "\n",
    "#counties_df\n",
    "\n",
    "#filter to only show NM and CO\n",
    "filtered_counties = counties_df[\n",
    "                    (counties_df['STATEFP'].isin(['08', '35'])) &\n",
    "                    (counties_df['NAME'].isin(['Colfax', 'Harding', 'Mora','Weld']))\n",
    "]\n",
    "\n",
    "# Display the filtered rows\n",
    "print(filtered_counties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'usfs_df' (DataFrame)\n",
      "Stored 'usfs_gdf' (GeoDataFrame)\n",
      "Stored 'studyarea_data' (str)\n",
      "Stored 'counties_gdf' (GeoDataFrame)\n",
      "Stored 'states_gdf' (GeoDataFrame)\n",
      "Stored 'states_df' (DataFrame)\n",
      "Stored 'counties_df' (DataFrame)\n",
      "Stored 'usfs_shp_path' (str)\n",
      "Stored 'counties_shp_path' (str)\n",
      "Stored 'states_shp_path' (str)\n"
     ]
    }
   ],
   "source": [
    "%store usfs_df usfs_gdf studyarea_data counties_gdf states_gdf states_df counties_df usfs_shp_path counties_shp_path states_shp_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
